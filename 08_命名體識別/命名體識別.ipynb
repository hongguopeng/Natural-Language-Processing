{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"網路架構.png\" style=\"width:1300px;height:700px;float:middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data.data'\n",
    "f = open(data_dir , 'r' , encoding = 'utf-8')\n",
    "all_data = f.read()\n",
    "data = []\n",
    "for text in all_data.split(':'):\n",
    "    if len(text) > 0:\n",
    "        data.append(text.split())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b代表開頭，i代表開頭以後的字\n",
    "# 文本 :   斯     洛     伐      克\n",
    "# tag :  b-loc  i-loc  i-loc   i-loc\n",
    "\n",
    "tags = ['o' ,               # 其他\n",
    "        'b-per' , 'i-per' , # 人\n",
    "        'b-loc' , 'i-loc' , # 位置\n",
    "        'b-org' , 'i-org']  # 公司\n",
    "\n",
    "tag_to_idx = {'tag_pad' : 0 ,\n",
    "              'o' : 1 ,\n",
    "              'b-per' : 2 , 'i-per' : 3 ,\n",
    "              'b-loc' : 4 , 'i-loc' : 5 ,\n",
    "              'b-org' : 6 , 'i-org' : 7}\n",
    "idx_to_tag = dict(zip(tag_to_idx.values() , tag_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算詞頻\n",
    "word_counts = {}\n",
    "for sentence in data:\n",
    "    for word in sentence:\n",
    "        word_lower = word.lower()\n",
    "        if word_lower not in tags:\n",
    "            if word_lower not in word_counts.keys():\n",
    "                word_counts[word_lower] = 1\n",
    "            else:\n",
    "                word_counts[word_lower] += 1\n",
    "\n",
    "vocab = [word for word , count in word_counts.items() if count >= 2] # 詞頻大於2，才列入考慮\n",
    "\n",
    "maxlen = max(len(sentence) for sentence in data) # 計算最長句子的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = dict((word , index + 2) for index , word in enumerate(vocab))\n",
    "word_to_idx['pad'] = 0\n",
    "word_to_idx['unk'] = 1\n",
    "idx_to_word = dict(zip(word_to_idx.values() , word_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將文本內容轉換為index\n",
    "x_article = []\n",
    "for sentence in data:\n",
    "    temp = []\n",
    "    for word in sentence[::2]:  # 取出偶數項，偶數項為文本內容\n",
    "        temp.append(word_to_idx.get(word.lower() , word_to_idx['unk']))\n",
    "    while len(temp) < maxlen:   # 補word_to_idx['pad']，直到長度為maxlen\n",
    "        temp.append(word_to_idx['pad'])\n",
    "    x_article.append(temp)\n",
    "x_article = np.array(x_article)\n",
    "\n",
    "# 將標籤轉換為index\n",
    "y_tag = []\n",
    "for sentence in data:\n",
    "    temp = []\n",
    "    for word in sentence[1::2]: # 取出奇數項，奇數項為標籤\n",
    "        temp.append(tag_to_idx.get(word.lower()))\n",
    "    while len(temp) < maxlen:   # 補tag_to_idx['tag_pad']，直到長度為maxlen\n",
    "        temp.append(tag_to_idx['tag_pad'])\n",
    "    y_tag.append(temp)\n",
    "y_tag = np.array(y_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(x_article))\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# 打亂順序\n",
    "x_article = x_article[indices]\n",
    "y_tag = y_tag[indices]\n",
    "\n",
    "# 切分訓練集與測試集\n",
    "split_at = len(x_article) - len(x_article) // 20\n",
    "x_article_train , x_article_val = x_article[:split_at] , x_article[split_at:]\n",
    "y_tag_train , y_tag_val = y_tag[:split_at] , y_tag[split_at:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 計算每種標籤出現的次數\n",
    "tag_counts = {}\n",
    "for sentence in data:\n",
    "    for word in sentence:\n",
    "        word_lower = word.lower()\n",
    "        if word_lower in tags:\n",
    "            if word_lower not in tag_counts.keys():\n",
    "                tag_counts[word_lower] = 1\n",
    "            else:\n",
    "                tag_counts[word_lower] += 1\n",
    "                \n",
    "fig , ax = plt.subplots(1 , 1 , figsize = (10 , 5))\n",
    "ax.bar(tag_counts.keys() , tag_counts.values() , alpha = 0.9 , width = 0.5 , facecolor = 'lightskyblue' , edgecolor = 'black')\n",
    "plt.xlabel('Tag' , fontsize = 20)\n",
    "plt.ylabel('Count' , fontsize = 20)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10)\n",
    "\n",
    "for a , b in zip(tag_counts.keys() , tag_counts.values()):  \n",
    "    plt.text(a , b + 0.005 , '{}'.format(b), ha = 'center' , va = 'bottom' , fontsize = 10)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本中標籤為'o'的字實在太多了，所以在計算accuracy時，若是把標籤為'o'的字考慮在內\n",
    "# 神經網路一定會將大量的字預測為'o'，導致準確率一定會非常高，但這樣根本看不出模型的訓練效果\n",
    "# 因此本程式中不考慮標籤為'o'的字，只考慮其他標籤是否預測正確(當然也不考慮'tag_pad')\n",
    "mask_train = np.where((y_tag_train != tag_to_idx['tag_pad']) & (y_tag_train != tag_to_idx['o']) ,\n",
    "                      np.ones_like(y_tag_train) ,\n",
    "                      np.zeros_like(y_tag_train))\n",
    "\n",
    "mask_val = np.where((y_tag_val != tag_to_idx['tag_pad']) & (y_tag_val !=  tag_to_idx['o']) ,\n",
    "                    np.ones_like(y_tag_val) ,\n",
    "                    np.zeros_like(y_tag_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "embedding_size = len(vocab) + 2\n",
    "embedding_dim = 210\n",
    "num_layers = 1\n",
    "batch_size = 64\n",
    "tag_size = len(tag_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入層\n",
    "input_data = tf.placeholder(tf.int32 , shape = [None , maxlen] , name = 'input_data')\n",
    "labels = tf.placeholder(tf.int32 , shape = [None , maxlen] , name = 'labels')\n",
    "batch_shape = tf.shape(input_data)[0]\n",
    "\n",
    "word_embedding = tf.get_variable(shape = [embedding_size , embedding_dim] ,\n",
    "                                 initializer = tf.glorot_uniform_initializer() ,\n",
    "                                 name = 'word_embedding')\n",
    "input_embedded = tf.nn.embedding_lookup(word_embedding , input_data)\n",
    "\n",
    "# 採用雙向LSTM\n",
    "cell_fw = tf.nn.rnn_cell.LSTMCell(embedding_dim)\n",
    "cell_bw = tf.nn.rnn_cell.LSTMCell(embedding_dim)\n",
    "(output_fw , output_bw) , state =\\\n",
    "tf.nn.bidirectional_dynamic_rnn(cell_fw , cell_bw ,\n",
    "                                input_embedded ,\n",
    "                                dtype = tf.float32)\n",
    "\n",
    "bilstm_out = tf.concat([output_fw , output_bw] , axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全連接層\n",
    "weight = tf.get_variable(shape = [2 * embedding_dim , tag_size] ,\n",
    "                         initializer = tf.glorot_uniform_initializer() ,\n",
    "                         name = 'weight' )\n",
    "\n",
    "bias = tf.get_variable(shape = [maxlen , tag_size],\n",
    "                       initializer = tf.zeros_initializer() ,\n",
    "                       name = 'bias')\n",
    "\n",
    "bilstm_out = tf.tensordot(bilstm_out , weight , axes = 1) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後在接上一個CRF層\n",
    "# 假如某個字的標籤序列是 ⇨'b-per' , 'i-per' , 'i-per' , 'i-per'\n",
    "# 而LSTM的輸出很可能是   ⇨'i-per' , 'b-per' , 'i-per' , 'i-per'\n",
    "# 而CRF層就是在修正這種錯誤\n",
    "log_likelihood , transition_params =\\\n",
    "tf.contrib.crf.crf_log_likelihood(bilstm_out ,\n",
    "                                  labels ,\n",
    "                                  tf.tile(np.array([maxlen]) , [batch_shape]))\n",
    "\n",
    "viterbi_sequence , viterbi_score =\\\n",
    "tf.contrib.crf.crf_decode(bilstm_out ,\n",
    "                          transition_params ,\n",
    "                          tf.tile(np.array([maxlen]) , [batch_shape]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-log_likelihood)\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "gradients = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 0\n",
      "training loss : 404.5178\n",
      "training_accuracy : 16.72%\n",
      "testing loss : 376.6792\n",
      "testing_accuracy : 14.78%\n",
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 200\n",
      "training loss : 13.2999\n",
      "training_accuracy : 16.93%\n",
      "testing loss : 13.4082\n",
      "testing_accuracy : 16.53%\n",
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 400\n",
      "training loss : 7.5903\n",
      "training_accuracy : 52.32%\n",
      "testing loss : 7.8986\n",
      "testing_accuracy : 57.08%\n",
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 600\n",
      "training loss : 5.6919\n",
      "training_accuracy : 61.95%\n",
      "testing loss : 5.6653\n",
      "testing_accuracy : 66.39%\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 0\n",
      "training loss : 4.9995\n",
      "training_accuracy : 70.67%\n",
      "testing loss : 4.8881\n",
      "testing_accuracy : 71.64%\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 200\n",
      "training loss : 3.5448\n",
      "training_accuracy : 78.68%\n",
      "testing loss : 4.2267\n",
      "testing_accuracy : 75.09%\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 400\n",
      "training loss : 3.4024\n",
      "training_accuracy : 76.49%\n",
      "testing loss : 3.7376\n",
      "testing_accuracy : 77.60%\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 600\n",
      "training loss : 3.1604\n",
      "training_accuracy : 77.88%\n",
      "testing loss : 3.4013\n",
      "testing_accuracy : 76.86%\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 0\n",
      "training loss : 2.6248\n",
      "training_accuracy : 88.86%\n",
      "testing loss : 3.0948\n",
      "testing_accuracy : 80.92%\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 200\n",
      "training loss : 2.2291\n",
      "training_accuracy : 84.95%\n",
      "testing loss : 2.8499\n",
      "testing_accuracy : 80.82%\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 400\n",
      "training loss : 2.3487\n",
      "training_accuracy : 79.80%\n",
      "testing loss : 2.6299\n",
      "testing_accuracy : 81.83%\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 600\n",
      "training loss : 2.1009\n",
      "training_accuracy : 87.32%\n",
      "testing loss : 2.4288\n",
      "testing_accuracy : 83.58%\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 0\n",
      "training loss : 1.8506\n",
      "training_accuracy : 92.67%\n",
      "testing loss : 2.3034\n",
      "testing_accuracy : 84.72%\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 200\n",
      "training loss : 1.5485\n",
      "training_accuracy : 88.09%\n",
      "testing loss : 2.1692\n",
      "testing_accuracy : 84.14%\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 400\n",
      "training loss : 1.6847\n",
      "training_accuracy : 86.42%\n",
      "testing loss : 2.0520\n",
      "testing_accuracy : 84.52%\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 600\n",
      "training loss : 1.5199\n",
      "training_accuracy : 90.27%\n",
      "testing loss : 1.9474\n",
      "testing_accuracy : 85.78%\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 0\n",
      "training loss : 1.4480\n",
      "training_accuracy : 93.84%\n",
      "testing loss : 1.8920\n",
      "testing_accuracy : 87.31%\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 200\n",
      "training loss : 1.2596\n",
      "training_accuracy : 89.66%\n",
      "testing loss : 1.7945\n",
      "testing_accuracy : 85.38%\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 400\n",
      "training loss : 1.1979\n",
      "training_accuracy : 88.08%\n",
      "testing loss : 1.7062\n",
      "testing_accuracy : 86.50%\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 600\n",
      "training loss : 1.1760\n",
      "training_accuracy : 91.74%\n",
      "testing loss : 1.6813\n",
      "testing_accuracy : 86.02%\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 0\n",
      "training loss : 1.2156\n",
      "training_accuracy : 96.19%\n",
      "testing loss : 1.6474\n",
      "testing_accuracy : 89.25%\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 200\n",
      "training loss : 1.0284\n",
      "training_accuracy : 89.66%\n",
      "testing loss : 1.5645\n",
      "testing_accuracy : 86.53%\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 400\n",
      "training loss : 0.8465\n",
      "training_accuracy : 91.06%\n",
      "testing loss : 1.5171\n",
      "testing_accuracy : 87.74%\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 600\n",
      "training loss : 0.9503\n",
      "training_accuracy : 91.45%\n",
      "testing loss : 1.5788\n",
      "testing_accuracy : 86.10%\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 0\n",
      "training loss : 0.9631\n",
      "training_accuracy : 96.48%\n",
      "testing loss : 1.4798\n",
      "testing_accuracy : 89.06%\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 200\n",
      "training loss : 0.7520\n",
      "training_accuracy : 94.04%\n",
      "testing loss : 1.4256\n",
      "testing_accuracy : 87.96%\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 400\n",
      "training loss : 0.5923\n",
      "training_accuracy : 94.37%\n",
      "testing loss : 1.3645\n",
      "testing_accuracy : 88.96%\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 600\n",
      "training loss : 0.7463\n",
      "training_accuracy : 94.69%\n",
      "testing loss : 1.5858\n",
      "testing_accuracy : 85.44%\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 0\n",
      "training loss : 0.7467\n",
      "training_accuracy : 96.48%\n",
      "testing loss : 1.3980\n",
      "testing_accuracy : 90.00%\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 200\n",
      "training loss : 0.5734\n",
      "training_accuracy : 94.67%\n",
      "testing loss : 1.3642\n",
      "testing_accuracy : 89.04%\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 400\n",
      "training loss : 0.4395\n",
      "training_accuracy : 94.70%\n",
      "testing loss : 1.2858\n",
      "testing_accuracy : 88.48%\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 600\n",
      "training loss : 0.5914\n",
      "training_accuracy : 95.58%\n",
      "testing loss : 1.4801\n",
      "testing_accuracy : 86.03%\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 0\n",
      "training loss : 0.4721\n",
      "training_accuracy : 96.48%\n",
      "testing loss : 1.2778\n",
      "testing_accuracy : 90.51%\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 200\n",
      "training loss : 0.4503\n",
      "training_accuracy : 96.24%\n",
      "testing loss : 1.3442\n",
      "testing_accuracy : 89.05%\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 400\n",
      "training loss : 0.3097\n",
      "training_accuracy : 95.36%\n",
      "testing loss : 1.2344\n",
      "testing_accuracy : 89.26%\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 600\n",
      "training loss : 0.4002\n",
      "training_accuracy : 95.58%\n",
      "testing loss : 1.3989\n",
      "testing_accuracy : 89.26%\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 0\n",
      "training loss : 0.3110\n",
      "training_accuracy : 96.77%\n",
      "testing loss : 1.2844\n",
      "testing_accuracy : 91.23%\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 200\n",
      "training loss : 0.3439\n",
      "training_accuracy : 96.55%\n",
      "testing loss : 1.3622\n",
      "testing_accuracy : 89.24%\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 400\n",
      "training loss : 0.2779\n",
      "training_accuracy : 95.70%\n",
      "testing loss : 1.3216\n",
      "testing_accuracy : 88.47%\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 600\n",
      "training loss : 0.4129\n",
      "training_accuracy : 93.81%\n",
      "testing loss : 1.3191\n",
      "testing_accuracy : 91.56%\n"
     ]
    }
   ],
   "source": [
    "# minibatch data index\n",
    "epochs = 10\n",
    "num = batch_size\n",
    "step = (math.ceil(len(x_article_train) / num)) * num\n",
    "temp = []\n",
    "j = 0\n",
    "index = []\n",
    "for ii in range(0 , step):\n",
    "    j = j + 1\n",
    "    if j > len(x_article_train):\n",
    "        j = j - (len(x_article_train))\n",
    "    temp.append(j)\n",
    "    if len(temp) == num:\n",
    "        index.append(temp)\n",
    "        temp = []\n",
    "index = list(np.array(index) - 1)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# 開始訓練\n",
    "train_loss_his = []\n",
    "for epoch_i in range(0 , epochs):\n",
    "    for batch_i in range(0 , len(index)):\n",
    "        batch_x_article = x_article_train[index[batch_i] , :]\n",
    "        batch_y_tag = y_tag_train[index[batch_i] , :]\n",
    "        _ , train_loss , pred_ner_train =\\\n",
    "        sess.run([train_op , loss , viterbi_sequence] ,\n",
    "                 feed_dict = {input_data : batch_x_article ,\n",
    "                              labels : batch_y_tag})\n",
    "\n",
    "        if batch_i % 200 == 0:\n",
    "            batch_mask = mask_train[index[batch_i] , :]\n",
    "            accuracy_train = np.sum((batch_y_tag == pred_ner_train) * batch_mask) / np.sum(batch_mask)\n",
    "\n",
    "            test_loss , pred_ner_test =\\\n",
    "            sess.run([loss , viterbi_sequence] ,\n",
    "                      feed_dict = {input_data : x_article_val ,\n",
    "                                   labels : y_tag_val})\n",
    "            accuracy_test = np.sum((y_tag_val == pred_ner_test) * mask_val) / np.sum(mask_val)\n",
    "\n",
    "            print('=' * 30)\n",
    "            print('epoch_i : {}'.format(epoch_i))\n",
    "            print('batch_i : {}'.format(batch_i))\n",
    "            print('training loss : {:.4f}'.format(train_loss))\n",
    "            print('training_accuracy : {:.2%}'.format(accuracy_train))\n",
    "            print('testing loss : {:.4f}'.format(test_loss))\n",
    "            print('testing_accuracy : {:.2%}'.format(accuracy_test))\n",
    "            train_loss_his.append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_set , true_tag_set , pred_tag_set = [] , [] , []\n",
    "for article ,  true_tag , pred_tag in zip(x_article_val , y_tag_val , pred_ner_test):\n",
    "    temp = []\n",
    "    for article_idx in article:\n",
    "        if article_idx == 0: break\n",
    "        temp.append(idx_to_word[article_idx])    \n",
    "    article_set.append(temp)\n",
    "    \n",
    "    temp = []\n",
    "    for tag_idx in true_tag:\n",
    "        if tag_idx == 0: break\n",
    "        temp.append(idx_to_tag[tag_idx])    \n",
    "    true_tag_set.append(temp)\n",
    "    \n",
    "    temp = []\n",
    "    for tag_idx in pred_tag:\n",
    "        if tag_idx == 0: break\n",
    "        temp.append(idx_to_tag[tag_idx])\n",
    "    pred_tag_set.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本內容 :\n",
      "他们还邀请联合国开发计划署专家潘德克先生讲授交通工程理论，请国内著名交通管理专家讲授交通管理现代化系统及交通信息控制系统理论。\n",
      "\n",
      "\n",
      "真實_Tag : \n",
      "o|o|o|o|o|b-org|i-org|i-org|i-org|i-org|i-org|i-org|i-org|o|o|b-per|i-per|i-per|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o\n",
      "\n",
      "預測_Tag : \n",
      "o|o|o|o|o|b-org|i-org|i-org|i-org|i-org|i-org|i-org|i-org|o|o|b-per|i-per|i-per|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o\n"
     ]
    }
   ],
   "source": [
    "article_3 = ''.join(article_set[3])\n",
    "print('文本內容 :')\n",
    "print('{}'.format(article_3))\n",
    "print('\\n')\n",
    "\n",
    "print('真實_Tag : \\n{}\\n'.format('|'.join(true_tag_set[3])))\n",
    "print('預測_Tag : \\n{}'.format('|'.join(pred_tag_set[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本內容 :\n",
      "加剧了黄河下游的断流和水患发生的可能性。\n",
      "\n",
      "\n",
      "真實_Tag : \n",
      "o|o|o|b-loc|i-loc|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o\n",
      "\n",
      "預測_Tag : \n",
      "o|o|o|b-loc|i-loc|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o\n"
     ]
    }
   ],
   "source": [
    "article_6 = ''.join(article_set[6])\n",
    "print('文本內容 :')\n",
    "print('{}'.format(article_6))\n",
    "print('\\n')\n",
    "\n",
    "print('真實_Tag : \\n{}\\n'.format('|'.join(true_tag_set[6])))\n",
    "print('預測_Tag : \\n{}'.format('|'.join(pred_tag_set[6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本內容 :\n",
      "其中，十分引人注目的是《华尔街日报》一改百多年来的严肃面孔，推出周末版“标准模式”；\n",
      "\n",
      "\n",
      "真實_Tag : \n",
      "o|o|o|o|o|o|o|o|o|o|o|o|b-org|i-org|i-org|i-org|i-org|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o\n",
      "\n",
      "預測_Tag : \n",
      "o|o|o|o|o|o|o|o|o|o|o|o|b-org|i-org|i-org|i-org|i-org|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o|o\n"
     ]
    }
   ],
   "source": [
    "article_30 = ''.join(article_set[30])\n",
    "print('文本內容 :')\n",
    "print('{}'.format(article_30))\n",
    "print('\\n')\n",
    "\n",
    "print('真實_Tag : \\n{}\\n'.format('|'.join(true_tag_set[30])))\n",
    "print('預測_Tag : \\n{}'.format('|'.join(pred_tag_set[30])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本內容 :\n",
      "1996年的欧洲杯赛又减到28％。\n",
      "\n",
      "\n",
      "真實_Tag : \n",
      "o|o|o|o|o|o|b-loc|i-loc|o|o|o|o|o|o|o|o|o\n",
      "\n",
      "預測_Tag : \n",
      "o|o|o|o|o|o|b-loc|i-loc|o|o|o|o|o|o|o|o|o\n"
     ]
    }
   ],
   "source": [
    "article_71 = ''.join(article_set[71])\n",
    "print('文本內容 :')\n",
    "print('{}'.format(article_71))\n",
    "print('\\n')\n",
    "\n",
    "print('真實_Tag : \\n{}\\n'.format('|'.join(true_tag_set[71])))\n",
    "print('預測_Tag : \\n{}'.format('|'.join(pred_tag_set[71])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
