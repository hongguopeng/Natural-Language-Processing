{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq_Attension\n",
    "刪除原數列中的奇數數字並將剩餘偶數數字複製一次\n",
    "<br>輸入 : [9 , 4 , 1 , 4 , 8 , 5 , 8 , 3 , 7 , 5 , 8 , 10 , 5]\n",
    "<br>輸出 : [4 , 4 , 8 , 8 , 8 , 10 , 4 , 4 , 8 , 8 , 8 , 10]\n",
    "<br><br>\n",
    "對比於「1_seq2seq_使用helper指令.ipynb」這支程式<br>\n",
    "加入Attention機制強化Seq2Seq後，可以明顯發現訓練的效果比起單純Seq2Seq還要好非常多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "# Number of Epochs\n",
    "epochs = 140\n",
    "# RNN Size\n",
    "rnn_hidden_unit = 50\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 15\n",
    "decoding_embedding_size = 15\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "vocab_size_sorce = 10 + 1  # 1~10 + 0\n",
    "vocab_size_target = 10 + 3 # 1~10 + 0 & 11 & 12\n",
    "max_len = 24\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備數據(將數字串中的奇數刪除，並將剩下的數字再複製一遍)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "GO = 11\n",
    "EOS = 12\n",
    "odd_list, even_list = [1, 3, 5, 7, 9] * 10, [2, 4, 6, 8, 10] * 10\n",
    "\n",
    "def get_batches(num_samples = batch_size , copy_sequence = True):  \n",
    "    num_odds = np.random.randint(low = 1 , high = max_len//2 , size = num_samples)\n",
    "    num_evens = np.random.randint(low = 1 , high = max_len//2 , size = num_samples)\n",
    "    batch_len_x = num_odds + num_evens\n",
    "    if copy_sequence:\n",
    "        batch_len_y = num_evens * 2 + 1  # append <EOS> (or prepend <GO>)\n",
    "    else:\n",
    "        batch_len_y = num_evens + 1  # append <EOS> (or prepend <GO>)\n",
    "\n",
    "    batch_max_length_x = np.max(batch_len_x)\n",
    "    batch_max_length_y = np.max(batch_len_y)\n",
    "\n",
    "    batch_data_x, batch_data_y = [], []\n",
    "    for i in range(0 , num_samples):\n",
    "        odds = random.sample(odd_list , num_odds[i])\n",
    "        evens = random.sample(even_list , num_evens[i])\n",
    "        sample_x = odds + evens\n",
    "        random.shuffle(sample_x)\n",
    "\n",
    "        sample_y = list(filter(lambda x: x % 2 == 0 , sample_x))\n",
    "        if copy_sequence:\n",
    "            sample_y += sample_y\n",
    "        sample_x = np.r_[sample_x , [PAD] * (batch_max_length_x - len(sample_x))]\n",
    "        sample_y = np.r_[sample_y , [EOS] , [PAD] * (batch_max_length_y - len(sample_y) - 1)]\n",
    "\n",
    "        batch_data_x.append(sample_x)\n",
    "        batch_data_y.append(sample_y)\n",
    "\n",
    "    batch_data_x = np.array(batch_data_x , dtype = np.int32)\n",
    "    batch_data_y = np.array(batch_data_y , dtype = np.int32)\n",
    "\n",
    "    return batch_data_x , batch_data_y , batch_len_x , batch_len_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸入層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [None , None] , name = 'inputs')\n",
    "targets = tf.placeholder(tf.int32, [None , None] , name = 'targets')\n",
    "lr = tf.placeholder(tf.float32 , name = 'learning_rate')\n",
    "\n",
    "source_sequence_length = tf.placeholder(tf.int32 , (None ,) , name = 'source_sequence_length')\n",
    "target_sequence_length = tf.placeholder(tf.int32 , (None ,) , name = 'target_sequence_length')\n",
    "\n",
    "# 決定target序列最大長度（之後target_sequence_length和source_sequence_length會作為feed_dict的參數）\n",
    "max_target_sequence_length = tf.reduce_max(target_sequence_length , name = 'max_target_len')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder embedding\n",
    "'''\n",
    "encoder_embed_input = tf.contrib.layers.embed_sequence(input_data , source_vocab_size , encoding_embedding_size) \n",
    "                                                  ⇕ 相當於\n",
    "encoder_embeddings = tf.Variable(tf.random_uniform([source_vocab_size , encoding_embedding_size]))\n",
    "encoder_embed_input = tf.nn.embedding_lookup(encoder_embeddings , input_data)\n",
    "\n",
    "若懶得寫兩行程式可以直接用tf.contrib.layers.embed_sequence這個函數\n",
    "介紹 : https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence\n",
    "'''\n",
    "encoder_embed_input = tf.contrib.layers.embed_sequence(input_data , vocab_size_sorce , encoding_embedding_size)\n",
    "\n",
    "# RNN cell\n",
    "def get_lstm_cell(rnn_hidden_unit):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(rnn_hidden_unit, \n",
    "                                        initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "    return lstm_cell\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([get_lstm_cell(rnn_hidden_unit) for _ in range(num_layers)])\n",
    "\n",
    "encoder_output, encoder_state = tf.nn.dynamic_rnn(cell, \n",
    "                                                  encoder_embed_input, \n",
    "                                                  sequence_length = source_sequence_length,\n",
    "                                                  dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder and Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理後的decoder輸入\n",
    "# 在batch中每一筆data最前面加上GO，並移除最後一個字，所以每一筆data的詞的數目並無改變\n",
    "ending = tf.identity(targets[: , 0:-1])\n",
    "decoder_input = tf.concat([tf.fill([batch_size, 1], GO), ending], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.contrib.seq2seq.TrainingHelper:(Training 階段，還有其他種類的Helper)\n",
    "### 訓練時採用teacher forcing，永遠把ground truth輸入給模型，不管模型前一步預測結果是否正確\n",
    "此函數為Decoder端用來訓練的參數，這個函數不會把t-1階段的輸出當作t階段的輸入，而是把target中的真實質直接輸入給RNN<br>\n",
    "主要參數是inputs與sequence_length，返回helper對象，可以做為Basic Decoder函數的參數\n",
    "<br><br><br>\n",
    "\n",
    "## tf.contrib.seq2seq.GreedyEmbeddingHelper:(Inference 階段，還有其他種類的Helper)\n",
    "### 它和TrainingHelper的區別在於它會把把t-1階段的輸出進行embedding後再輸入給RNN，並且經過embedding層作為下一時刻的輸入\n",
    "• greedy decoding：每一次把模型認為概率最大的 token 輸入給下一時間步<br>\n",
    "• beam search decoding：每次保留 top k 的預測結果，解碼得到（近似） k best 序列 <br>\n",
    "• sample decoding：每一步從模型預測的概率分布裏隨機采一個 token 輸入給下一時間步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Embedding，需要對target數據進行embedding，再傳入Decoder中的RNN\n",
    "decoder_embeddings = tf.Variable(tf.random_uniform([vocab_size_target , decoding_embedding_size]))\n",
    "decoder_embed_input = tf.nn.embedding_lookup(decoder_embeddings , decoder_input)\n",
    "\n",
    "# 2. 建造Decoder中的RNN單元\n",
    "def get_decoder_cell(rnn_hidden_unit):\n",
    "    decoder_cell = tf.contrib.rnn.LSTMCell(rnn_hidden_unit,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "    return decoder_cell\n",
    "cell = tf.contrib.rnn.MultiRNNCell([get_decoder_cell(rnn_hidden_unit) for _ in range(num_layers)])\n",
    " \n",
    "# 3. Output全連接層\n",
    "output_layer = Dense(vocab_size_target ,\n",
    "                     kernel_initializer = tf.truncated_normal_initializer(mean = 0.0 , stddev = 0.1))\n",
    "\n",
    "# 4. 構造Attention \n",
    "attn_mech = tf.contrib.seq2seq.LuongAttention(num_units = rnn_hidden_unit ,\n",
    "                                              memory = encoder_output ,\n",
    "                                              memory_sequence_length = source_sequence_length)\n",
    "\n",
    "\n",
    "attn_decoder = tf.contrib.seq2seq.AttentionWrapper(cell = cell ,\n",
    "                                                   attention_mechanism = attn_mech , \n",
    "                                                   attention_layer_size = rnn_hidden_unit , \n",
    "                                                   alignment_history = True) # 可輸出Attention matrix\n",
    " \n",
    "initial_state = attn_decoder.zero_state(batch_size , tf.float32).clone(cell_state = encoder_state)\n",
    "\n",
    "# 5. Training decoder\n",
    "with tf.variable_scope('decoder'):\n",
    "    # tf.contrib.seq2seq.TrainingHelper即是採用Teacher Forcing的方法\n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs = decoder_embed_input,\n",
    "                                                        sequence_length = target_sequence_length,\n",
    "                                                        time_major = False)\n",
    "    \n",
    "    # 構造decoder\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(attn_decoder,\n",
    "                                                       training_helper,\n",
    "                                                       initial_state,\n",
    "                                                       output_layer) \n",
    "    \n",
    "    training_decoder_output ,\\\n",
    "    training_final_state ,\\\n",
    "    training_final_sequence_lengths =\\\n",
    "    tf.contrib.seq2seq.dynamic_decode(training_decoder,                                          \n",
    "                                      impute_finished = True,\n",
    "                                      maximum_iterations = max_target_sequence_length)\n",
    "    \n",
    "    attention_matrices = training_final_state.alignment_history.stack(name = 'train_attention_matrix')\n",
    "    \n",
    "with tf.variable_scope('decoder' , reuse = True):\n",
    "    \n",
    "    tf.get_variable_scope().reuse_variables() \n",
    "    \n",
    "    # 創建一個常量tensor並覆制為batch_size的大小\n",
    "    start_tokens = tf.tile(tf.constant([GO] , dtype=tf.int32),\n",
    "                           [batch_size] , \n",
    "                           name = 'start_tokens')\n",
    "    \n",
    "    # GreedyEmbeddingHelper採取argmax抽樣演算法來得到輸出id，並且經過embedding層作為下一時刻的輸入\n",
    "    predicting_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings,\n",
    "                                                                 start_tokens,\n",
    "                                                                 EOS)\n",
    "    \n",
    "    predicting_decoder = tf.contrib.seq2seq.BasicDecoder(attn_decoder,\n",
    "                                                         predicting_helper,\n",
    "                                                         initial_state,\n",
    "                                                         output_layer)\n",
    "    \n",
    "    predicting_decoder_output ,\\\n",
    "    predicting_final_state ,\\\n",
    "    predicting_final_sequence_lengths =\\\n",
    "    tf.contrib.seq2seq.dynamic_decode(predicting_decoder,\n",
    "                                      impute_finished = True,\n",
    "                                      maximum_iterations = max_target_sequence_length)  \n",
    "    \n",
    "    # 產生attention矩陣，有助於最後可視化結果\n",
    "    predicting_attention_matrices = predicting_final_state.alignment_history.stack(name = 'inference_attention_matrix')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出Attention matrix => [decoder_steps, batch_size, encoder_steps]\n",
    "predicting_attention_matrices = predicting_final_state.alignment_history.stack(name = 'predicting_attention_matrix')     \n",
    "    \n",
    "training_logits = tf.identity(training_decoder_output.rnn_output , 'logits')\n",
    "predicting_logits = tf.identity(predicting_decoder_output.sample_id , name='predictions')\n",
    "\n",
    "masks = tf.sequence_mask(target_sequence_length , \n",
    "                         max_target_sequence_length, \n",
    "                         dtype = tf.float32, \n",
    "                         name = 'masks')\n",
    "\n",
    "with tf.variable_scope('optimization'):        \n",
    "    # Loss function\n",
    "    cost = tf.contrib.seq2seq.sequence_loss(training_logits,\n",
    "                                            targets,\n",
    "                                            masks)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch : 99 \n",
      "Training Loss : 1.806\n",
      "New Record!\n",
      "Source : [ 6  9 10  7  8  7  2 10  7  7  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 6 10  8  2 10  6 10  8  2 10 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  2  2  2  2  2  2  2  2  2  2  2  2 12  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 199 \n",
      "Training Loss : 1.471\n",
      "New Record!\n",
      "Source : [8 6 8 1 6 9 2 4 1 5 7 1 7 1 3 1 0 0 0 0]\n",
      "Target : [ 8  6  8  6  2  4  8  6  8  6  2  4 12  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 6  6  6  6  6  6  6  6  6  6  6 12  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 299 \n",
      "Training Loss : 1.293\n",
      "New Record!\n",
      "Source : [ 2  5  3  4  7  9  1  9 10  3  9  6  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 2  4 10  6  2  4 10  6 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  4  4  2  2  2  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 399 \n",
      "Training Loss : 1.191\n",
      "New Record!\n",
      "Source : [ 3  1  4  7  7 10  2  5  8  5  4  6  6  3  8  4  3  0  0  0  0]\n",
      "Target : [ 4 10  2  8  4  6  6  8  4  4 10  2  8  4  6  6  8  4 12  0  0  0  0]\n",
      "Predict: [ 4  4 10 10  4  6  6  6  6  6  6  6  6  6  6  6  6  4 12  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 499 \n",
      "Training Loss : 1.097\n",
      "New Record!\n",
      "Source : [ 6  2  3  2  6  4  8  6  6  4  2 10  1  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 6  2  2  6  4  8  6  6  4  2 10  6  2  2  6  4  8  6  6  4  2 10 12]\n",
      "Predict: [ 6  2  2  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  4  4  4 12]\n",
      "\n",
      "\n",
      "Batch : 599 \n",
      "Training Loss : 0.971\n",
      "New Record!\n",
      "Source : [9 2 5 1 1 3 7 5 8 9 8 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 2  8  8  2  8  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  8  8  8  8  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 699 \n",
      "Training Loss : 0.774\n",
      "New Record!\n",
      "Source : [7 2 1 7 5 7 5 9 1 3 9 6 2 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 2  6  2  2  6  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  6  2  2  2  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 799 \n",
      "Training Loss : 0.517\n",
      "New Record!\n",
      "Source : [ 7  1  7  1 10  7 10  7  3  2  2  8  8  0  0  0  0  0  0  0  0  0]\n",
      "Target : [10 10  2  2  8  8 10 10  2  2  8  8 12  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10 10  2  2  8  8 10 10  2  2  8  8 12  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 899 \n",
      "Training Loss : 0.212\n",
      "New Record!\n",
      "Source : [6 2 5 8 4 4 8 7 8 2 2 8 9 8 0 0 0 0 0 0 0]\n",
      "Target : [ 6  2  8  4  4  8  8  2  2  8  8  6  2  8  4  4  8  8  2  2  8  8 12]\n",
      "Predict: [ 6  2  8  4  4  8  8  2  2  8  8  6  2  8  4  4  8  2  2  2  8  8 12]\n",
      "\n",
      "\n",
      "Batch : 999 \n",
      "Training Loss : 0.197\n",
      "New Record!\n",
      "Source : [2 1 5 7 6 8 9 3 5 1 7 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 2  6  8  2  6  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  6  8  2  6  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1099 \n",
      "Training Loss : 0.050\n",
      "New Record!\n",
      "Source : [3 3 7 3 7 7 8 7 5 1 5 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 8  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 8  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1199 \n",
      "Training Loss : 0.035\n",
      "New Record!\n",
      "Source : [ 7  1  7 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [10 10 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10 10 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1299 \n",
      "Training Loss : 0.022\n",
      "New Record!\n",
      "Source : [ 3  5  7  1  5  3 10  7  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [10 10 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10 10 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1399 \n",
      "Training Loss : 0.098\n",
      "No Improvement.\n",
      "Source : [10  4  1  2  4 10  6  5  9  6  4  3  7  5  1  3  8  7  0  0  0  0]\n",
      "Target : [10  4  2  4 10  6  6  4  8 10  4  2  4 10  6  6  4  8 12  0  0  0  0]\n",
      "Predict: [10  4  2  4 10  6  6  4  8 10  4  2  4  4 10  6  6  4  8 12  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1499 \n",
      "Training Loss : 0.081\n",
      "New Record!\n",
      "Source : [ 9  2  8  6  5  8  4  6  9  4  7  5 10 10  9  0  0  0  0  0  0]\n",
      "Target : [ 2  8  6  8  4  6  4 10 10  2  8  6  8  4  6  4 10 10 12  0  0  0  0]\n",
      "Predict: [ 2  8  6  8  4  6  4 10 10  2  8  6  8  4  6  4 10 10 12  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1599 \n",
      "Training Loss : 0.015\n",
      "New Record!\n",
      "Source : [ 8  7  7  7 10  2  1  7  4  2  5  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 8 10  2  4  2  8 10  2  4  2 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 8 10  2  4  2  8 10  2  4  2 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1699 \n",
      "Training Loss : 0.010\n",
      "New Record!\n",
      "Source : [ 5  2  3  9 10  1  2  8  6  3  7 10  7  4  2  9 10  7  0  0  0]\n",
      "Target : [ 2 10  2  8  6 10  4  2 10  2 10  2  8  6 10  4  2 10 12  0  0  0  0]\n",
      "Predict: [ 2 10  2  8  6 10  4  2 10  2 10  2  8  6 10  4  2 10 12  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1799 \n",
      "Training Loss : 0.007\n",
      "New Record!\n",
      "Source : [ 6 10  5  3  5  5  9  8  8  3  4  4 10  9  2  0  0  0  0  0  0]\n",
      "Target : [ 6 10  8  8  4  4 10  2  6 10  8  8  4  4 10  2 12  0  0  0  0  0  0]\n",
      "Predict: [ 6 10  8  8  4  4 10  2  6 10  8  8  4  4 10  2 12  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1899 \n",
      "Training Loss : 0.005\n",
      "New Record!\n",
      "Source : [4 7 3 1 4 2 8 1 7 9 2 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 4  4  2  8  2  4  4  2  8  2 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 4  4  2  8  2  4  4  2  8  2 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 1999 \n",
      "Training Loss : 0.004\n",
      "New Record!\n",
      "Source : [ 5  1  6  3  9  7  1  6 10  3  2  2  1  9  8  9  8  0  0  0  0  0]\n",
      "Target : [ 6  6 10  2  2  8  8  6  6 10  2  2  8  8 12  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 6  6 10  2  2  8  8  6  6 10  2  2  8  8 12  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2099 \n",
      "Training Loss : 0.004\n",
      "New Record!\n",
      "Source : [ 2 10  4  6  6  8  7  9  5  3  8  6  4  7  3  5  4  1  9  3  0  0]\n",
      "Target : [ 2 10  4  6  6  8  8  6  4  4  2 10  4  6  6  8  8  6  4  4 12  0  0]\n",
      "Predict: [ 2 10  4  6  6  8  8  6  4  4  2 10  4  6  6  8  8  6  4  4 12  0  0]\n",
      "\n",
      "\n",
      "Batch : 2199 \n",
      "Training Loss : 0.003\n",
      "No Improvement.\n",
      "Source : [ 1  6  1  5  2 10 10 10  3  4  4  6  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 6  2 10 10 10  4  4  6  6  2 10 10 10  4  4  6 12  0  0  0  0  0  0]\n",
      "Predict: [ 6  2 10 10 10  4  4  6  6  2 10 10 10  4  4  6 12  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2299 \n",
      "Training Loss : 0.003\n",
      "New Record!\n",
      "Source : [ 1  5  9  5 10  7  6  7  7  2  6  2  3  5  3  0  0  0  0  0  0]\n",
      "Target : [10  6  2  6  2 10  6  2  6  2 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10  6  2  6  2 10  6  2  6  2 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2399 \n",
      "Training Loss : 0.002\n",
      "No Improvement.\n",
      "Source : [3 2 9 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 2  8  2  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  8  2  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2499 \n",
      "Training Loss : 0.002\n",
      "New Record!\n",
      "Source : [5 9 3 9 3 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 8  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 8  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2599 \n",
      "Training Loss : 0.002\n",
      "New Record!\n",
      "Source : [ 5  6 10 10  3  7  3  3  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 6 10 10  2  6 10 10  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 6 10 10  2  6 10 10  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2699 \n",
      "Training Loss : 0.003\n",
      "No Improvement.\n",
      "Source : [6 6 1 9 4 3 2 2 4 9 6 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 6  6  4  2  2  4  6  6  6  4  2  2  4  6 12  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 6  6  4  2  2  4  6  6  6  4  2  2  4  6 12  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2799 \n",
      "Training Loss : 0.384\n",
      "New Record!\n",
      "Source : [9 7 3 1 5 5 2 1 6 5 3 7 4 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 2  6  4  2  6  4 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 2  6  4  2  6  4 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2899 \n",
      "Training Loss : 0.059\n",
      "New Record!\n",
      "Source : [ 1  1  5  9  7  1 10  7  1  8  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [10  8 10  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10  8 10  8 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 2999 \n",
      "Training Loss : 0.015\n",
      "New Record!\n",
      "Source : [6 6 9 8 3 3 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 6  6  8  4  6  6  8  4 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 6  6  8  4  6  6  8  4 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch : 3099 \n",
      "Training Loss : 0.008\n",
      "New Record!\n",
      "Source : [ 2  4  8  6  4  3  6 10 10  4  7  2  6  5  0  0  0  0  0  0  0  0]\n",
      "Target : [ 2  4  8  6  4  6 10 10  4  2  6  2  4  8  6  4  6 10 10  4  2  6 12]\n",
      "Predict: [ 2  4  8  6  4  6 10 10  4  2  6  2  4  8  6  4  6 10 10  4  2  6 12]\n",
      "\n",
      "\n",
      "Batch : 3199 \n",
      "Training Loss : 0.005\n",
      "New Record!\n",
      "Source : [8 5 9 3 9 4 9 8 7 6 5 2 8 7 1 0 0 0 0 0 0]\n",
      "Target : [ 8  4  8  6  2  8  8  4  8  6  2  8 12  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 8  4  8  6  2  8  8  4  8  6  2  8 12  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 3299 \n",
      "Training Loss : 0.004\n",
      "New Record!\n",
      "Source : [10  5  3  7  7  3 10  7  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [10 10  2 10 10  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10 10  2 10 10  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 3399 \n",
      "Training Loss : 0.003\n",
      "New Record!\n",
      "Source : [10  5  6  9  6  7  7  1  9  2  4  1 10  3  1  0  0  0  0  0  0]\n",
      "Target : [10  6  6  2  4 10 10  6  6  2  4 10 12  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [10  6  6  2  4 10 10  6  6  2  4 10 12  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 3499 \n",
      "Training Loss : 0.002\n",
      "No Improvement.\n",
      "Source : [ 5  2  4  4  2  2  5 10  6  6  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Target : [ 2  4  4  2  2 10  6  6  2  4  4  2  2 10  6  6 12  0  0  0  0  0  0]\n",
      "Predict: [ 2  4  4  2  2 10  6  6  2  4  4  2  2 10  6  6 12  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 3599 \n",
      "Training Loss : 0.002\n",
      "New Record!\n",
      "Source : [ 9  6  1 10  8  6 10  2  4  4  7  8  8  5  3  9  6  7  0]\n",
      "Target : [ 6 10  8  6 10  2  4  4  8  8  6  6 10  8  6 10  2  4  4  8  8  6 12]\n",
      "Predict: [ 6 10  8  6 10  2  4  4  8  8  6  6 10  8  6 10  2  4  4  8  8  6 12]\n",
      "\n",
      "\n",
      "Batch : 3699 \n",
      "Training Loss : 0.002\n",
      "New Record!\n",
      "Source : [ 8  1  5  9  7 10  7  3  3  3  1 10  0  0  0  0  0  0  0  0]\n",
      "Target : [ 8 10 10  8 10 10 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 8 10 10  8 10 10 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 3799 \n",
      "Training Loss : 0.001\n",
      "New Record!\n",
      "Source : [6 3 7 1 3 1 8 8 5 9 2 0 0 0 0 0 0 0 0 0]\n",
      "Target : [ 6  8  8  2  6  8  8  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 6  8  8  2  6  8  8  2 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 3899 \n",
      "Training Loss : 0.001\n",
      "New Record!\n",
      "Source : [ 3  2  7 10  2  6  7  9  2  4  3  7  8  7  6  4  4  3  9  8  0]\n",
      "Target : [ 2 10  2  6  2  4  8  6  4  4  8  2 10  2  6  2  4  8  6  4  4  8 12]\n",
      "Predict: [ 2 10  2  6  2  4  8  6  4  4  8  2 10  2  6  2  4  8  6  4  4  8 12]\n",
      "\n",
      "\n",
      "Batch : 3999 \n",
      "Training Loss : 0.001\n",
      "New Record!\n",
      "Source : [ 5  9  4  6  1  5  8  4  7  2 10  8  9  3  3  1  0  0  0  0  0  0]\n",
      "Target : [ 4  6  8  4  2 10  8  4  6  8  4  2 10  8 12  0  0  0  0  0  0  0  0]\n",
      "Predict: [ 4  6  8  4  2 10  8  4  6  8  4  2 10  8 12  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 4099 \n",
      "Training Loss : 0.001\n",
      "No Improvement.\n",
      "Source : [10  2  9  3  4  6  2  4  6  4 10  8  2  3  0  0  0  0  0  0  0]\n",
      "Target : [10  2  4  6  2  4  6  4 10  8  2 10  2  4  6  2  4  6  4 10  8  2 12]\n",
      "Predict: [10  2  4  6  2  4  6  4 10  8  2 10  2  4  6  2  4  6  4 10  8  2 12]\n",
      "\n",
      "\n",
      "Batch : 4199 \n",
      "Training Loss : 0.001\n",
      "New Record!\n",
      "Source : [ 2  1  3  3  7  5  2  5  9  8  2  6  5  2  4  5 10  9  0  0  0]\n",
      "Target : [ 2  2  8  2  6  2  4 10  2  2  8  2  6  2  4 10 12  0  0  0  0  0  0]\n",
      "Predict: [ 2  2  8  2  6  2  4 10  2  2  8  2  6  2  4 10 12  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 4299 \n",
      "Training Loss : 0.001\n",
      "No Improvement.\n",
      "Source : [ 7 10  6  2  4  5  7  9 10  9  2  8  1  9  1  3  0  0  0  0  0  0]\n",
      "Target : [10  6  2  4 10  2  8 10  6  2  4 10  2  8 12  0  0  0  0  0  0  0  0]\n",
      "Predict: [10  6  2  4 10  2  8 10  6  2  4 10  2  8 12  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 4399 \n",
      "Training Loss : 0.001\n",
      "No Improvement.\n",
      "Source : [ 1  9  5 10  6  3  2  4 10  2  7  7 10  6  3  1  0  0  0  0]\n",
      "Target : [10  6  2  4 10  2 10  6 10  6  2  4 10  2 10  6 12  0  0  0  0  0  0]\n",
      "Predict: [10  6  2  4 10  2 10  6 10  6  2  4 10  2 10  6 12  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Batch : 4499 \n",
      "Training Loss : 0.001\n",
      "No Improvement.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_ = []\n",
    "stop_early = 0\n",
    "for batch_i in range(0 , 5000):\n",
    "    \n",
    "    # 在每進行一個epoch前，把每個batch的index先決定出來\n",
    "    pad_train_source_batch , pad_train_target_batch, train_source_length , train_target_length = get_batches()\n",
    "\n",
    "        \n",
    "    _ , loss , predicting_logits_result =\\\n",
    "    sess.run([train_op, cost , predicting_logits], \n",
    "             feed_dict = {input_data : pad_train_source_batch ,\n",
    "                          targets : pad_train_target_batch ,\n",
    "                          source_sequence_length: train_source_length , \n",
    "                          target_sequence_length : train_target_length  ,   \n",
    "                          lr: learning_rate})\n",
    "    \n",
    "    loss_.append(loss)    \n",
    "    if len(loss_) == 100:\n",
    "        loss_ = np.array(loss_)\n",
    "        print('\\nBatch : {} \\nTraining Loss : {:.3f}'.format(batch_i , loss_.mean()))\n",
    "        if loss <= loss_.mean():\n",
    "            print('New Record!') \n",
    "            stop_early = 0\n",
    "        else:\n",
    "            print('No Improvement.')\n",
    "            stop_early += 1\n",
    "            if stop_early == 3:\n",
    "                break            \n",
    "        loss_ = []\n",
    "        \n",
    "        print('Source : {}'.format(pad_train_source_batch[0 , :]))\n",
    "        print('Target : {}'.format(pad_train_target_batch[0 , :]))\n",
    "        print('Predict: {}\\n'.format(predicting_logits_result[0 , :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10, 6, 7, 8, 6, 2, 5, 9, 1, 10, 6, 9, 9, 1, 2, 2, 4, 0, 0, 0, 0]\n",
      "[4, 10, 6, 8, 6, 2, 10, 6, 2, 2, 4, 4, 10, 6, 8, 6, 2, 10, 6, 2, 2, 4, 12]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "att , predicting_logits_ = sess.run([predicting_attention_matrices , predicting_logits], \n",
    "                                     feed_dict = {input_data : pad_train_source_batch ,\n",
    "                                                  targets : pad_train_target_batch ,\n",
    "                                                  source_sequence_length: train_source_length , \n",
    "                                                  target_sequence_length : train_target_length})    \n",
    "\n",
    "# 隨機取一個樣本 i 畫出注意力矩陣\n",
    "i = 50\n",
    "matrix = att[:, i, :].T\n",
    "src = pad_train_source_batch[i, :]\n",
    "tgt = predicting_logits_[i , :]    \n",
    "\n",
    "src_letter , tgt_letter = [] , []\n",
    "for item in src:\n",
    "    src_letter.append(item)\n",
    "for item in tgt :\n",
    "    tgt_letter.append(item)\n",
    "print(src_letter)\n",
    "print(tgt_letter)\n",
    "\n",
    "df = pd.DataFrame(matrix , index = src_letter , columns = tgt_letter)\n",
    "plt.figure(figsize=(10 , 8))\n",
    "ax = sns.heatmap(df , linewidths = 1)\n",
    "ax.set_xlabel('output')\n",
    "ax.set_ylabel('source')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.yticks(rotation = 0)\n",
    "ax.set_title('Attention heatmap')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
