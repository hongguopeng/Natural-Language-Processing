{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq_Attension\n",
    "實現機器翻譯(Machine Translation)，輸入一句英文句子，輸出一句法文句子\n",
    "<br>輸入 : his least liked fruit is the apple , but your least liked is the strawberry .\n",
    "<br>輸出 : son fruit est moins aimé la pomme , mais votre moins aimé est la fraise .\n",
    "<br>在這支程式中加入Attension機制，強化Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一般的Seq2Seq模型的inference階段中，如果Sequence中在t時刻中產生錯誤的值，在t時刻之後的輸入狀態將會受到影響，而該誤差會隨著生成過程不斷向後累積；而Scheduled Sampling以一定概率將Decoder自己產生的值作為Decoder端的輸入，這樣即使前面產生錯誤的值，其目標仍然是最大化真實目標序列的概率，模型會朝著正確的方向進<br>\n",
    "\n",
    "在訓練早期Scheduled Sampling主要使用target中的真實值作為Decoder端的輸入，可以將模型從隨機初始化的狀態快速引導至一個合理的狀態；隨著訓練的進行，該方法會逐漸更多地使用Decoder自己產生的值作為Decoder端的輸入，以解決數據分布不一致的問題<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import random\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English source data\n",
    "f_eng = open('data/small_vocab_en' , 'r' , encoding = 'utf-8')\n",
    "source_letter = []\n",
    "source_sentence = []\n",
    "while True:\n",
    "    raw = f_eng.readline()\n",
    "    if raw == '' : break\n",
    "\n",
    "    sentence = raw.split('\\n')[0] \n",
    "    temp_sentence = []\n",
    "    for word in sentence.split(' '):\n",
    "        if len(word) != 0:\n",
    "            source_letter.append(word.lower())\n",
    "            temp_sentence.append(word.lower())\n",
    "    source_sentence.append(temp_sentence)    \n",
    "\n",
    "    \n",
    "# French target data\n",
    "f_fre = open('data/small_vocab_fr', 'r', encoding='utf-8')       \n",
    "target_letter = []\n",
    "target_sentence = []\n",
    "while True:\n",
    "    raw = f_fre.readline()\n",
    "    if raw == '' : break\n",
    "\n",
    "    sentence = raw.split('\\n')[0]   \n",
    "    temp_sentence = []\n",
    "    for word in sentence.split(' '):\n",
    "        if len(word) != 0:\n",
    "            target_letter.append(word.lower())\n",
    "            temp_sentence.append(word.lower())\n",
    "    target_sentence.append(temp_sentence)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 數據預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_words = ['<PAD>' , '<UNK>' , '<GO>' , '<EOS>']\n",
    "\n",
    "# 建造英文詞庫\n",
    "source_letter = list(set(source_letter)) + special_words[:2] # 加入 '<PAD>' , '<UNK>'              \n",
    "source_letter_to_int = {word : idx for idx , word in enumerate(source_letter)}   \n",
    "source_int_to_letter = {idx : word for idx , word in enumerate(source_letter)}   \n",
    "\n",
    "# 建造法文詞庫\n",
    "target_letter = list(set(target_letter)) + special_words # 加入 '<PAD>' , '<UNK>' , '<GO>' , '<EOS>'       \n",
    "target_letter_to_int = {word : idx for idx , word in enumerate(target_letter)}   \n",
    "target_int_to_letter = {idx : word for idx , word in enumerate(target_letter)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將所有字母轉換成index\n",
    "source_int = []\n",
    "for sentence in source_sentence:\n",
    "    temp = []\n",
    "    for letter in sentence:\n",
    "        if letter in source_letter_to_int.keys():\n",
    "            temp.append(source_letter_to_int[letter])  \n",
    "        else:\n",
    "            temp.append(source_letter_to_int['<UNK>'])\n",
    "    source_int.append(temp)           \n",
    "            \n",
    "target_int = []\n",
    "for sentence in target_sentence:\n",
    "    temp = []\n",
    "    for letter in sentence:\n",
    "        if letter in target_letter_to_int.keys():\n",
    "            temp.append(target_letter_to_int[letter])\n",
    "        else:\n",
    "            temp.append(target_letter_to_int['<UNK>'])\n",
    "    temp.append(target_letter_to_int['<EOS>'])          \n",
    "    target_int.append(temp)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "# Number of Epochs\n",
    "epochs = 200\n",
    "# Batch Size\n",
    "batch_size = 130\n",
    "# RNN Size\n",
    "rnn_hidden_unit = 128\n",
    "# Number of Layers\n",
    "num_layers = 1\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 100\n",
    "decoding_embedding_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸入層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32 , [None , None] , name = 'inputs')\n",
    "targets = tf.placeholder(tf.int32 , [None , None] , name = 'targets')\n",
    "from_model_or_target = tf.placeholder(tf.float32 , [] , name = 'from_model_or_target')\n",
    "\n",
    "source_sequence_length = tf.placeholder(tf.int32 , [None ,] , name = 'source_sequence_length')\n",
    "target_sequence_length = tf.placeholder(tf.int32 , [None ,] , name = 'target_sequence_length')\n",
    "# 決定target序列最大長度（之後target_sequence_length和source_sequence_length會作為feed_dict的參數）\n",
    "max_target_sequence_length = tf.reduce_max(target_sequence_length , name = 'max_target_len')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要對source數據進行embedding，再傳入Decoder中的RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data: 輸入tensor\n",
    "# rnn_hidden_unit: rnn隱層結點數量\n",
    "# num_layers: rnn cell的層數\n",
    "# source_sequence_length: source數據的序列長度\n",
    "# source_vocab_size: source數據的詞庫大小\n",
    "# encoding_embedding_size: embedding的向量維度\n",
    "\n",
    "# Encoder embedding\n",
    "'''\n",
    "encoder_embed_input = tf.contrib.layers.embed_sequence(input_data , source_vocab_size , encoding_embedding_size) \n",
    "                                                  ⇕ 相當於\n",
    "encoder_embeddings = tf.Variable(tf.random_uniform([source_vocab_size , encoding_embedding_size]))\n",
    "encoder_embed_input = tf.nn.embedding_lookup(encoder_embeddings , input_data)\n",
    "\n",
    "若懶得寫兩行程式可以直接用tf.contrib.layers.embed_sequence這個函數\n",
    "介紹 : https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence\n",
    "'''\n",
    "source_vocab_size = len(source_letter_to_int)\n",
    "encoder_embeddings = tf.Variable(tf.random_uniform([source_vocab_size , encoding_embedding_size]))\n",
    "encoder_embed_input = tf.nn.embedding_lookup(encoder_embeddings , input_data)\n",
    "\n",
    "def get_lstm_cell(rnn_hidden_unit):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(rnn_hidden_unit, \n",
    "                                        initializer = tf.random_uniform_initializer(-0.1 , 0.1))\n",
    "    return lstm_cell\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([get_lstm_cell(rnn_hidden_unit) for _ in range(num_layers)])\n",
    "\n",
    "encoder_output, encoder_state = tf.nn.dynamic_rnn(cell, \n",
    "                                                  encoder_embed_input, \n",
    "                                                  sequence_length = source_sequence_length,\n",
    "                                                  dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder and Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理後的decoder輸入\n",
    "# 在batch中每一筆data最前面加上<GO>，並移除最後一個字，所以每一筆data的詞的數目並無改變\n",
    "\n",
    "# cut掉最後一個字\n",
    "# ending = tf.strided_slice(targets , [0, 0] , [batch_size, -1] , [1, 1]) # 等同於 ending = tf.identity(targets[: , 0:-1])\n",
    "ending = tf.identity(targets[: , 0:-1])\n",
    "decoder_input = tf.concat([tf.fill([batch_size, 1] , target_letter_to_int['<GO>']) , ending] , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper:(Training 階段，還有其他種類的Helper)\n",
    "### 訓練時採用scheduled sampling，永遠把ground truth輸入給模型，不管模型前一步預測結果是否正確\n",
    "train-decoder不再一直都是真實的lable數據作為下一個時刻的輸入<br>\n",
    "train-decoder會以一個機率P選擇模型自身的輸出作為下一個預測的輸入，以1-p選擇真實標記作為下一個預測的輸入<br>\n",
    "scheduled sampling，即機率P在訓練的過程中是變化的<br>\n",
    "一開始訓練不充分，先讓P小一些，盡量使用真實的label作為輸入，隨著訓練的進行，將P增大，採用自身的輸出作為下一個預測的輸入<br>\n",
    "隨著訓練的進行，P越來越大，train-decoder模型最終變來和inference-decoder預測模型一樣，消除了train-decoder與inference-decoder之間的差異\n",
    "<br><br><br>\n",
    "\n",
    "### tf.contrib.seq2seq.GreedyEmbeddingHelper:(Inference 階段，還有不同sample手段的Helper)\n",
    "### 它和TrainingHelper的區別在於它會把t-1時刻的輸出經過embedding層作為t時刻的輸入\n",
    "• greedy decoding：每一次把模型認為機率最大的 token 輸入給下一時刻<br>\n",
    "• beam search decoding：每次保留 top k 的預測結果，解碼得到（近似） k best 序列 <br>\n",
    "• sample decoding：每一步從模型預測的機率分布中隨機取樣一個 token 輸入給下一時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding_embedding_size: embedding的向量維度\n",
    "# num_layers: rnn cell的層數\n",
    "# rnn_size: RNN單元的隱層結點數量\n",
    "# target_sequence_length: target數據序列長度\n",
    "# max_target_sequence_length: target數據序列最大長度\n",
    "# encoder_state: encoder端編碼的狀態向量\n",
    "# decoder_input: decoder端輸入\n",
    "\n",
    "# 1. Embedding，需要對target數據進行embedding，再傳入Decoder中的RNN\n",
    "target_vocab_size = len(target_letter_to_int)\n",
    "decoder_embeddings = tf.Variable(tf.random_uniform([target_vocab_size , decoding_embedding_size]))\n",
    "decoder_embed_input = tf.nn.embedding_lookup(decoder_embeddings , decoder_input)\n",
    "\n",
    "# 2. 建造Decoder中的RNN單元\n",
    "def get_decoder_cell(rnn_hidden_unit):\n",
    "    decoder_cell = tf.contrib.rnn.LSTMCell(rnn_hidden_unit,\n",
    "                                           initializer = tf.random_uniform_initializer(-0.1 , 0.1))\n",
    "    return decoder_cell\n",
    "cell = tf.contrib.rnn.MultiRNNCell([get_decoder_cell(rnn_hidden_unit) for _ in range(num_layers)])\n",
    " \n",
    "# 3. Output全連接層\n",
    "output_layer = Dense(target_vocab_size,\n",
    "                     kernel_initializer = tf.truncated_normal_initializer(mean = 0.0 , stddev = 0.1))\n",
    " \n",
    "# 4. 加入Attention機制\n",
    "attn_mech = tf.contrib.seq2seq.LuongAttention(num_units = rnn_hidden_unit ,\n",
    "                                              memory = encoder_output ,\n",
    "                                              memory_sequence_length = source_sequence_length)\n",
    "\n",
    "\n",
    "attn_decoder = tf.contrib.seq2seq.AttentionWrapper(cell = cell ,\n",
    "                                                   attention_mechanism = attn_mech , \n",
    "                                                   attention_layer_size = rnn_hidden_unit , \n",
    "                                                   alignment_history = True)\n",
    " \n",
    "initial_state = attn_decoder.zero_state(batch_size , tf.float32).clone(cell_state = encoder_state)\n",
    "\n",
    "\n",
    "# 5. Training decoder\n",
    "with tf.variable_scope('decoder'):\n",
    "    # tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper即是採用scheduled sampling的方法\n",
    "    training_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(inputs = decoder_embed_input ,\n",
    "                                                                          sequence_length = target_sequence_length,\n",
    "                                                                          embedding = decoder_embeddings ,\n",
    "                                                                          sampling_probability = from_model_or_target ,\n",
    "                                                                          time_major = False)\n",
    "\n",
    "    # 建造decoder\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(attn_decoder ,\n",
    "                                                       training_helper ,\n",
    "                                                       initial_state ,\n",
    "                                                       output_layer) \n",
    "    \n",
    "    # decoder_output包含 rnn_output 與 sample_id\n",
    "    # rnn_output: [batch_size, decoder_targets_length, vocab_size]，保存decode每個時刻每個單詞的概率，可以用來計算loss\n",
    "    # sample_id: [batch_size], tf.int32，保存最終的編碼結果。可以表示最後的答案\n",
    "    training_decoder_output ,\\\n",
    "    training_final_state ,\\\n",
    "    training_final_sequence_lengths =\\\n",
    "    tf.contrib.seq2seq.dynamic_decode(training_decoder,                                          \n",
    "                                      impute_finished = True,\n",
    "                                      maximum_iterations = max_target_sequence_length)\n",
    "    \n",
    "    attention_matrices = training_final_state.alignment_history.stack(name = 'train_attention_matrix')\n",
    "\n",
    "    \n",
    "with tf.variable_scope('decoder'):\n",
    "    \n",
    "    tf.get_variable_scope().reuse_variables() \n",
    "    \n",
    "    # 創建一個常量tensor並覆制為batch_size的大小\n",
    "    start_tokens = tf.tile(tf.constant([target_letter_to_int['<GO>']], dtype=tf.int32) ,\n",
    "                           [batch_size] , \n",
    "                           name = 'start_tokens')\n",
    "    \n",
    "    # GreedyEmbeddingHelper採取argmax抽樣演算法來得到輸出id，並且經過embedding層作為下一時刻的輸入\n",
    "    predicting_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings ,\n",
    "                                                                 start_tokens ,\n",
    "                                                                 target_letter_to_int['<EOS>'])\n",
    "    \n",
    "    predicting_decoder = tf.contrib.seq2seq.BasicDecoder(attn_decoder ,\n",
    "                                                         predicting_helper ,\n",
    "                                                         initial_state ,\n",
    "                                                         output_layer)\n",
    "  \n",
    "    predicting_decoder_output ,\\\n",
    "    predicting_final_state ,\\\n",
    "    predicting_final_sequence_lengths=\\\n",
    "    tf.contrib.seq2seq.dynamic_decode(predicting_decoder,\n",
    "                                      impute_finished = True,\n",
    "                                      maximum_iterations = max_target_sequence_length)  \n",
    "\n",
    "    # 產生attention矩陣，有助於最後可視化結果\n",
    "    predicting_attention_matrices = predicting_final_state.alignment_history.stack(name = 'inference_attention_matrix')                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hong guo peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\hong guo peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "training_logits = tf.identity(training_decoder_output.rnn_output ,  name = 'logits')\n",
    "predicting_logits = tf.identity(predicting_decoder_output.sample_id ,  name = 'predictions')\n",
    "\n",
    "'''\n",
    "target_sequence_length : [4 , 2 , 3]\n",
    "\n",
    "max_target_sequence_length : 8\n",
    "\n",
    "=> masks的輸出長這樣 : 1 1 1 1 0 0 0 0  (4)\n",
    "                       1 1 0 0 0 0 0 0  (2)\n",
    "                       1 1 1 0 0 0 0 0  (3)\n",
    "-> 0的部分代表是補0的地方，不列入loss的計算，可以加快運算速度\n",
    "'''                \n",
    "               \n",
    "masks = tf.sequence_mask(target_sequence_length , \n",
    "                         max_target_sequence_length, \n",
    "                         dtype = tf.float32, \n",
    "                         name = 'masks')\n",
    "\n",
    "\n",
    "with tf.variable_scope('optimization'):        \n",
    "    # Loss function\n",
    "    cost = tf.contrib.seq2seq.sequence_loss(training_logits,\n",
    "                                            targets,\n",
    "                                            masks)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad , -1. , 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(source , target , index = None , on_train = False):  \n",
    "    if on_train:\n",
    "        source = np.array(source)[index]    \n",
    "        target = np.array(target)[index]   \n",
    "    else:\n",
    "        source = np.array(source)\n",
    "        target = np.array(target)\n",
    "        \n",
    "    # 決定source與target中的最大長度\n",
    "    source_max_length , target_max_length = 0 , 0  \n",
    "    for vob_source , vob_target in zip(source , target):\n",
    "        if len(vob_source) > source_max_length:\n",
    "            source_max_length = len(vob_source)    \n",
    "        if len(vob_target) > target_max_length:\n",
    "            target_max_length = len(vob_target)  \n",
    " \n",
    "    # 分別對source與target補source_letter_to_int['<PAD>']與target_letter_to_int['<PAD>']到最大長度  \n",
    "    source_pad , target_pad = [] , []\n",
    "    source_len , target_len = [] , []\n",
    "    for source_sentence , target_sentence in zip(source , target):\n",
    "        source_len.append(len(source_sentence)) # 收集source中每個sencentence的長度\n",
    "        temp_source = source_sentence.copy()\n",
    "        while len(temp_source) < source_max_length:\n",
    "            temp_source.append(source_letter_to_int['<PAD>']) \n",
    "        source_pad.append(temp_source)\n",
    "        \n",
    "        target_len.append(len(target_sentence)) # 收集target中每個sencentence的長度\n",
    "        temp_target = target_sentence.copy()\n",
    "        while len(temp_target) < target_max_length:\n",
    "            temp_target.append(target_letter_to_int['<PAD>']) \n",
    "        target_pad.append(temp_target) \n",
    "        \n",
    "    return np.array(source_pad) , np.array(target_pad) , np.array(source_len) , np.array(target_len)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將數據集分割為train和validation\n",
    "train_source = source_int[batch_size:]\n",
    "train_target = target_int[batch_size:]\n",
    "# 留出一個batch進行驗證\n",
    "valid_source = source_int[:batch_size]\n",
    "valid_target = target_int[:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Epoch : 0/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.821 \n",
      "Validation loss : 0.869\n",
      "******************************\n",
      "Source  : they are going to france next june .\n",
      "Target  : ils vont en france en juin prochain .\n",
      "Predict : ils vont aller en chine juin .\n",
      "\n",
      "==============================\n",
      "Epoch : 1/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.454 \n",
      "Validation loss : 0.512\n",
      "******************************\n",
      "Source  : we like oranges , mangoes , and grapes .\n",
      "Target  : nous aimons les oranges , les mangues et les raisins .\n",
      "Predict : nous aimons les oranges , les mangues et les raisins .\n",
      "\n",
      "==============================\n",
      "Epoch : 2/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.334 \n",
      "Validation loss : 0.389\n",
      "******************************\n",
      "Source  : he saw a old yellow truck .\n",
      "Target  : il a vu un vieux camion jaune .\n",
      "Predict : il a vu un petit camion jaune .\n",
      "\n",
      "==============================\n",
      "Epoch : 3/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.263 \n",
      "Validation loss : 0.277\n",
      "******************************\n",
      "Source  : he dislikes lemons , grapes , and mangoes.\n",
      "Target  : il déteste les citrons , les raisins et les mangues .\n",
      "Predict : il déteste les citrons , les raisins et les mangues .\n",
      "\n",
      "==============================\n",
      "Epoch : 4/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.222 \n",
      "Validation loss : 0.221\n",
      "******************************\n",
      "Source  : california is never wet during november , and it is sometimes pleasant in september .\n",
      "Target  : california est jamais humide en novembre , et il est parfois agréable en septembre .\n",
      "Predict : californie est jamais humide au novembre , novembre il et il agréable en septembre . septembre .\n",
      "\n",
      "==============================\n",
      "Epoch : 5/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.196 \n",
      "Validation loss : 0.201\n",
      "******************************\n",
      "Source  : new jersey is usually quiet during fall , but it is usually warm in april .\n",
      "Target  : new jersey est généralement calme au cours de l' automne , mais il est généralement chaud en avril .\n",
      "Predict : new jersey est généralement calme au cours de l' automne , mais il est généralement chaud en avril .\n",
      "\n",
      "==============================\n",
      "Epoch : 6/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.231 \n",
      "Validation loss : 0.181\n",
      "******************************\n",
      "Source  : france is snowy during may , and it is never busy in autumn .\n",
      "Target  : la france est la neige au mois de mai , et il est jamais trop de monde à l' automne .\n",
      "Predict : la france est la neige au mois , mai , et il est jamais occupé en monde à l' automne .\n",
      "\n",
      "==============================\n",
      "Epoch : 7/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.172 \n",
      "Validation loss : 0.151\n",
      "******************************\n",
      "Source  : their least liked fruit is the banana , but her least liked is the peach .\n",
      "Target  : leur fruit est moins aimé la banane , mais elle est moins aimé la pêche .\n",
      "Predict : leurs fruits moins aimé est la banane , mais elle est moins aimé la pêche .\n",
      "\n",
      "==============================\n",
      "Epoch : 8/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.174 \n",
      "Validation loss : 0.195\n",
      "******************************\n",
      "Source  : france is wonderful during november , but it is sometimes hot in september .\n",
      "Target  : france est merveilleux au mois de novembre , mais il est parfois chaud en septembre .\n",
      "Predict : france est merveilleux au mois de novembre , mais il est parfois chaud en septembre .\n",
      "\n",
      "==============================\n",
      "Epoch : 9/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.177 \n",
      "Validation loss : 0.131\n",
      "******************************\n",
      "Source  : we like strawberries , bananas , and oranges .\n",
      "Target  : nous aimons les fraises , les bananes et les oranges .\n",
      "Predict : nous aimons les fraises , les bananes et les oranges .\n",
      "\n",
      "==============================\n",
      "Epoch : 10/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 0 \n",
      "Training Loss : 0.039 \n",
      "Validation loss : 0.024\n",
      "******************************\n",
      "Source  : paris is relaxing during december , but it is usually chilly in july .\n",
      "Target  : paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "Predict : paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "\n",
      "==============================\n",
      "Epoch : 11/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 1 \n",
      "Training Loss : 0.167 \n",
      "Validation loss : 0.155\n",
      "******************************\n",
      "Source  : the united states is usually chilly during july , and it is usually freezing in november .\n",
      "Target  : les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "Predict : les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "\n",
      "==============================\n",
      "Epoch : 12/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 1 \n",
      "Training Loss : 0.153 \n",
      "Validation loss : 0.117\n",
      "******************************\n",
      "Source  : california is never cold during february , but it is sometimes freezing in june .\n",
      "Target  : californie ne fait jamais froid en février , mais il est parfois le gel en juin .\n",
      "Predict : californie ne fait jamais froid en février , mais il est parfois le gel en juin .\n",
      "\n",
      "==============================\n",
      "Epoch : 13/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 1 \n",
      "Training Loss : 0.141 \n",
      "Validation loss : 0.112\n",
      "******************************\n",
      "Source  : the apple is our least favorite fruit , but the mango is their least favorite .\n",
      "Target  : la pomme est notre fruit préféré moins , mais la mangue est leur moins préférée .\n",
      "Predict : la pomme est notre fruit préféré moins , mais la mangue est leur moins préférée .\n",
      "\n",
      "==============================\n",
      "Epoch : 14/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 1 \n",
      "Training Loss : 0.144 \n",
      "Validation loss : 0.109\n",
      "******************************\n",
      "Source  : india is chilly during summer , and it is sometimes beautiful in september .\n",
      "Target  : l' inde est froid pendant l' été , et il est parfois beau en septembre .\n",
      "Predict : l' inde est froid pendant l' été , et il est parfois beau en septembre .\n",
      "\n",
      "==============================\n",
      "Epoch : 15/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 1 \n",
      "Training Loss : 0.030 \n",
      "Validation loss : 0.020\n",
      "******************************\n",
      "Source  : he saw a old yellow truck .\n",
      "Target  : il a vu un vieux camion jaune .\n",
      "Predict : il a vu un vieux camion jaune .\n",
      "\n",
      "==============================\n",
      "Epoch : 16/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 2 \n",
      "Training Loss : 0.130 \n",
      "Validation loss : 0.101\n",
      "******************************\n",
      "Source  : china is never rainy during november , and it is quiet in january .\n",
      "Target  : chine est jamais pluvieux en novembre , et il est calme en janvier .\n",
      "Predict : chine est jamais pluvieux en novembre , et il et calme en janvier .\n",
      "\n",
      "==============================\n",
      "Epoch : 17/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 2 \n",
      "Training Loss : 0.024 \n",
      "Validation loss : 0.016\n",
      "******************************\n",
      "Source  : she likes peaches , limes , and mangoes .\n",
      "Target  : elle aime les pêches , citrons verts et les mangues .\n",
      "Predict : elle aime les pêches , citrons verts et les mangues .\n",
      "\n",
      "==============================\n",
      "Epoch : 18/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 3 \n",
      "Training Loss : 0.021 \n",
      "Validation loss : 0.015\n",
      "******************************\n",
      "Source  : paris is usually chilly during fall , but it is sometimes rainy in july .\n",
      "Target  : paris est généralement froid à l'automne , mais il est parfois pluvieux en juillet .\n",
      "Predict : paris est généralement froid à l'automne , mais il est parfois pluvieux en juillet .\n",
      "\n",
      "==============================\n",
      "Epoch : 19/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 4 \n",
      "Training Loss : 0.017 \n",
      "Validation loss : 0.014\n",
      "******************************\n",
      "Source  : california is usually quiet during march , and it is usually hot in june .\n",
      "Target  : california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "Predict : california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "\n",
      "==============================\n",
      "Epoch : 20/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 5 \n",
      "Training Loss : 0.032 \n",
      "Validation loss : 0.019\n",
      "******************************\n",
      "Source  : paris is usually chilly during fall , but it is sometimes rainy in july .\n",
      "Target  : paris est généralement froid à l'automne , mais il est parfois pluvieux en juillet .\n",
      "Predict : paris est généralement froid à l'automne , mais il est parfois pluvieux en juillet .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Epoch : 21/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 6 \n",
      "Training Loss : 0.013 \n",
      "Validation loss : 0.012\n",
      "******************************\n",
      "Source  : china is warm during spring , and it is sometimes cold in february .\n",
      "Target  : chine est chaud au printemps , et il est parfois froid en février .\n",
      "Predict : chine est chaud au printemps , et il est parfois froid en février .\n",
      "\n",
      "==============================\n",
      "Epoch : 22/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 7 \n",
      "Training Loss : 0.016 \n",
      "Validation loss : 0.011\n",
      "******************************\n",
      "Source  : the grapefruit is my most loved fruit , but the banana is her most loved .\n",
      "Target  : le pamplemousse est mon fruit le plus cher , mais la banane est la plus aimée .\n",
      "Predict : le pamplemousse est mon fruit le plus cher , mais la banane est la plus aimée .\n",
      "\n",
      "==============================\n",
      "Epoch : 23/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 8 \n",
      "Training Loss : 0.011 \n",
      "Validation loss : 0.012\n",
      "******************************\n",
      "Source  : china is sometimes pleasant during march , but it is usually nice in may .\n",
      "Target  : la chine est parfois agréable au mois de mars , mais il est généralement agréable en mai .\n",
      "Predict : la chine est parfois agréable au mois de mars , mais il est généralement agréable en mai .\n",
      "\n",
      "==============================\n",
      "Epoch : 24/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 9 \n",
      "Training Loss : 0.009 \n",
      "Validation loss : 0.014\n",
      "******************************\n",
      "Source  : paris is wonderful during march , but it is usually pleasant in june .\n",
      "Target  : paris est merveilleux au mois de mars , mais il est généralement agréable en juin .\n",
      "Predict : paris est merveilleux au mois de mars , mais il est généralement agréable en juin .\n",
      "\n",
      "==============================\n",
      "Epoch : 25/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 10 \n",
      "Training Loss : 0.008 \n",
      "Validation loss : 0.014\n",
      "******************************\n",
      "Source  : he likes strawberries , oranges , and limes .\n",
      "Target  : il aime les fraises , les oranges et les citrons verts .\n",
      "Predict : il aime les fraises , les oranges et les citrons verts .\n",
      "\n",
      "==============================\n",
      "Epoch : 26/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 11 \n",
      "Training Loss : 0.009 \n",
      "Validation loss : 0.011\n",
      "******************************\n",
      "Source  : california is usually freezing during december , and it is busy in april .\n",
      "Target  : la californie est le gel habituellement en décembre , et il est occupé en avril .\n",
      "Predict : la californie est le gel habituellement en décembre , et il est occupé en avril .\n",
      "\n",
      "==============================\n",
      "Epoch : 27/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 12 \n",
      "Training Loss : 0.012 \n",
      "Validation loss : 0.016\n",
      "******************************\n",
      "Source  : india is sometimes cold during march , but it is sometimes hot in january .\n",
      "Target  : l' inde est parfois froid au mois de mars , mais il est parfois chaud en janvier .\n",
      "Predict : l' inde est parfois froid au mois de mars , mais il est parfois chaud en janvier .\n",
      "\n",
      "==============================\n",
      "Epoch : 28/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 13 \n",
      "Training Loss : 0.005 \n",
      "Validation loss : 0.012\n",
      "******************************\n",
      "Source  : china is cold during fall , but it is usually relaxing in november .\n",
      "Target  : chine est froid à l'automne , mais il est relaxant habituellement en novembre .\n",
      "Predict : chine est froid pendant l' automne , mais il est relaxant habituellement en novembre .\n",
      "\n",
      "==============================\n",
      "Epoch : 29/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 14 \n",
      "Training Loss : 0.010 \n",
      "Validation loss : 0.012\n",
      "******************************\n",
      "Source  : we like oranges , mangoes , and grapes .\n",
      "Target  : nous aimons les oranges , les mangues et les raisins .\n",
      "Predict : nous aimons les oranges , les mangues et les raisins .\n",
      "\n",
      "==============================\n",
      "Epoch : 30/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 15 \n",
      "Training Loss : 0.005 \n",
      "Validation loss : 0.014\n",
      "******************************\n",
      "Source  : she likes mangoes , grapefruit , and pears .\n",
      "Target  : elle aime la mangue , le pamplemousse et les poires .\n",
      "Predict : elle aime la mangue , le pamplemousse et les poires .\n",
      "\n",
      "==============================\n",
      "Epoch : 31/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 16 \n",
      "Training Loss : 0.007 \n",
      "Validation loss : 0.012\n",
      "******************************\n",
      "Source  : new jersey is chilly during autumn , and it is sometimes pleasant in spring .\n",
      "Target  : new jersey est froid au cours de l' automne , et il est parfois agréable au printemps .\n",
      "Predict : new jersey est froid au cours de l' automne , et il est parfois agréable au printemps .\n",
      "\n",
      "==============================\n",
      "Epoch : 32/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 17 \n",
      "Training Loss : 0.010 \n",
      "Validation loss : 0.012\n",
      "******************************\n",
      "Source  : france is usually quiet during november , but it is sometimes warm in february .\n",
      "Target  : la france est généralement calme en novembre , mais il est parfois chaud en février .\n",
      "Predict : la france est généralement calme en novembre , mais il est parfois chaud en février .\n",
      "\n",
      "==============================\n",
      "Epoch : 33/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 18 \n",
      "Training Loss : 0.008 \n",
      "Validation loss : 0.007\n",
      "******************************\n",
      "Source  : france is snowy during may , and it is never busy in autumn .\n",
      "Target  : la france est la neige au mois de mai , et il est jamais trop de monde à l' automne .\n",
      "Predict : la france est la neige au mois de mai , et il est jamais trop de monde à l' automne .\n",
      "\n",
      "==============================\n",
      "Epoch : 34/200 \n",
      "Batch : 1058/1059 \n",
      "stop_early : 19 \n",
      "Training Loss : 0.004 \n",
      "Validation loss : 0.010\n",
      "******************************\n",
      "Source  : the lemon is my most loved fruit , but the strawberry is our most loved .\n",
      "Target  : le citron est mon fruit le plus aimé , mais la fraise est notre plus aimé .\n",
      "Predict : le citron est mon fruit le plus aimé , mais la fraise est notre plus aimé .\n",
      "\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "prob = 1e-3\n",
    "alpha = 1.5\n",
    "stop_early = 0\n",
    "for epoch_i in range(0 , epochs):\n",
    "    \n",
    "    # 在每進行一個epoch前，把每個batch的index先決定出來\n",
    "    batch_index = []\n",
    "    temp = []\n",
    "    count = 0 \n",
    "    while len(batch_index) <= 1059: \n",
    "        temp.append(count)\n",
    "        count += 1\n",
    "        if len(temp) == batch_size:\n",
    "            batch_index.append(temp)\n",
    "            temp = []\n",
    "        if count == len(train_source):\n",
    "            count = 0\n",
    "            \n",
    "    coin_tossing = np.random.choice(a = 2 , \n",
    "                                    size = 1 , \n",
    "                                    replace = True , \n",
    "                                    p = [prob , 1 - prob])[0]\n",
    "    if alpha * prob < 1  : prob = alpha * prob # p會隨著epoch增加越來越大\n",
    "    elif alpha * prob > 1: prob = 1.\n",
    "\n",
    "    for batch_i in range(0 , 1059):\n",
    "        train_source_batch_pad , \\\n",
    "        train_target_batch_pad , \\\n",
    "        train_source_batch_length , \\\n",
    "        train_target_batch_length = get_batches(source = train_source ,\n",
    "                                                target = train_target , \n",
    "                                                index = batch_index[batch_i] , \n",
    "                                                on_train = True)\n",
    "        \n",
    "        _ , loss =\\\n",
    "        sess.run([train_op , cost],\n",
    "                 feed_dict = {input_data : train_source_batch_pad ,\n",
    "                              targets : train_target_batch_pad ,\n",
    "                              source_sequence_length : train_source_batch_length ,\n",
    "                              target_sequence_length : train_target_batch_length , \n",
    "                              from_model_or_target : coin_tossing})\n",
    "        \n",
    "    valid_source_pad , \\\n",
    "    valid_target_pad , \\\n",
    "    valid_source_length , \\\n",
    "    valid_target_length = get_batches(source = valid_source ,\n",
    "                                      target = valid_target)\n",
    "\n",
    "    validation_loss , predicting_logits_result =\\\n",
    "    sess.run([cost , predicting_logits] ,\n",
    "             feed_dict = {input_data : valid_source_pad ,\n",
    "                          targets : valid_target_pad ,\n",
    "                          source_sequence_length : valid_source_length , \n",
    "                          target_sequence_length : valid_target_length , \n",
    "                          from_model_or_target : coin_tossing})\n",
    "\n",
    "    print('=' *  30)\n",
    "    print('Epoch : {}/{} \\nBatch : {}/{} \\nstop_early : {} \\nTraining Loss : {:.3f} \\nValidation loss : {:.3f}'\n",
    "          .format(epoch_i , epochs ,  \n",
    "                  batch_i , len(train_source) // batch_size , \n",
    "                  stop_early , loss , validation_loss))\n",
    "\n",
    "    index = np.random.randint(batch_size) # 隨機決定一筆data，查看翻譯的結果\n",
    "\n",
    "    source_visualization = []\n",
    "    for i in valid_source_pad[index]:\n",
    "        if source_int_to_letter[i] == '<PAD>': break\n",
    "        source_visualization.append(source_int_to_letter[i])\n",
    "    source_visualization = ' '.join(source_visualization)\n",
    "\n",
    "    target_visualization = []\n",
    "    for i in valid_target_pad[index]:\n",
    "        if target_int_to_letter[i] == '<EOS>': break\n",
    "        target_visualization.append(target_int_to_letter[i])\n",
    "    target_visualization = ' '.join(target_visualization)\n",
    "\n",
    "    predict_visualization = []\n",
    "    for i in predicting_logits_result[index]:\n",
    "        if target_int_to_letter[i] == '<EOS>': break\n",
    "        predict_visualization.append(target_int_to_letter[i])\n",
    "    predict_visualization = ' '.join(predict_visualization)\n",
    "\n",
    "    print('*' *  30)    \n",
    "    print('Source  : {}'.format(source_visualization))\n",
    "    print('Target  : {}'.format(target_visualization))\n",
    "    print('Predict : {}\\n'.format(predict_visualization))\n",
    "    \n",
    "    if coin_tossing == 0:\n",
    "        stop_early += 1\n",
    "\n",
    "    if stop_early == 20: # 當coin_tossing為0的次數為20時即停止計算\n",
    "        break\n",
    "\n",
    "# 保存模型\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess , 'trained_model/save_net')\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mango is your least liked fruit , but the apple is my least liked . <PAD>\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme . <EOS> janvier janvier janvier janvier janvier\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att , predicting_logits_ = sess.run([predicting_attention_matrices , predicting_logits], \n",
    "                                     feed_dict = {input_data : valid_source_pad ,\n",
    "                                                  targets : valid_target_pad ,\n",
    "                                                  source_sequence_length : valid_source_length , \n",
    "                                                  target_sequence_length : valid_target_length , \n",
    "                                                  from_model_or_target : coin_tossing})    \n",
    "\n",
    "\n",
    "# 隨機取一個樣本 i 畫出注意力矩陣\n",
    "i = 4\n",
    "matrix = att[: , i , ].T\n",
    "src = train_source_batch_pad[i , :]\n",
    "tgt = predicting_logits_[i , :]    \n",
    "\n",
    "src_letter , tgt_letter = [] , []\n",
    "for item in src:\n",
    "    src_letter.append(source_int_to_letter[item])\n",
    "for item in tgt :\n",
    "    tgt_letter.append(target_int_to_letter[item])\n",
    "print(' '.join(src_letter))\n",
    "print(' '.join(tgt_letter))\n",
    "\n",
    "df = pd.DataFrame(matrix , index = src_letter , columns = tgt_letter)\n",
    "plt.figure(figsize=(10 , 8))\n",
    "ax = sns.heatmap(df , linewidths = 1)\n",
    "ax.set_xlabel('output')\n",
    "ax.set_ylabel('source')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.yticks(rotation = 0)\n",
    "ax.set_title('Attention heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model\\save_net\n",
      "輸入的英文句子 : i dislike grapefruit , lemons , and peaches .\n",
      "google翻譯的法文句子 : je n'aime pamplemousses , les citrons et les pêches .\n",
      "model翻譯的法文句子  : je n'aime pamplemousses , les citrons et les pêches .\n"
     ]
    }
   ],
   "source": [
    "import os    \n",
    "sess = tf.Session()\n",
    "new_saver = tf.train.import_meta_graph(os.path.join('trained_model/save_net.meta'))\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(os.path.join('trained_model')))\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "input_data = graph.get_tensor_by_name('inputs:0')\n",
    "targets = graph.get_tensor_by_name('targets:0')\n",
    "source_sequence_length = graph.get_tensor_by_name('source_sequence_length:0')\n",
    "target_sequence_length = graph.get_tensor_by_name('target_sequence_length:0')\n",
    "logits = graph.get_tensor_by_name('predictions:0')\n",
    "from_model_or_target = graph.get_tensor_by_name('from_model_or_target:0')\n",
    "\n",
    "input_sentence = 'i dislike grapefruit , lemons , and peaches .'\n",
    "test_source = []\n",
    "for letter in input_sentence.split(' '):\n",
    "    if letter in source_letter_to_int.keys():\n",
    "        test_source.append(source_letter_to_int[letter])\n",
    "    elif letter not in source_letter_to_int.values():\n",
    "        test_source.append(source_letter_to_int['<UNK>'])\n",
    "test_source = [test_source] * batch_size\n",
    "test_source_length = [len(i) for i in test_source]\n",
    "           \n",
    "test_target = [0 for _ in range(0 , 100)] # test_target輸入的值可以隨便選，只要長度大於test_source即可\n",
    "test_target = [test_target] * batch_size\n",
    "test_target_length = [len(i) for i in test_target]\n",
    "\n",
    "test_source = np.array(test_source)\n",
    "test_target = np.array(test_target)\n",
    "test_source_length = np.array(test_source_length)\n",
    "test_target_length = np.array(test_target_length)\n",
    "\n",
    "answer = sess.run(logits, feed_dict = {input_data : test_source ,\n",
    "                                       targets : test_target ,\n",
    "                                       source_sequence_length : test_source_length ,\n",
    "                                       target_sequence_length : test_target_length , \n",
    "                                       from_model_or_target : coin_tossing})\n",
    "\n",
    "answer = answer[0 , :]\n",
    "answer_to_letter = []\n",
    "for num in answer:\n",
    "    if target_int_to_letter[num] == '<EOS>': break\n",
    "    answer_to_letter.append(target_int_to_letter[num])\n",
    "\n",
    "print('輸入的英文句子 : {}'.format(input_sentence))  \n",
    "print('google翻譯的法文句子 : {}'.format(\"je n'aime pamplemousses , les citrons et les pêches .\"))  \n",
    "print('model翻譯的法文句子  : {}'.format(' '.join(answer_to_letter)))      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
